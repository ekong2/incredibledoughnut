---
title: "Modern Data Mining - HW 2"
author:
- Aditi Jayashankar
- Eddie Kong
- Sahana Vijaya Prasad
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.height=5, fig.width=11, warning = F)
if(!require('pacman')) {
  install.packages('pacman')
}
pacman::p_load(glmnet, leaps, car, tidyverse, mapproj)

# constants for homework assignments
hw_num <- 2
hw_due_date <- "10 October, 2017"
```

## Overview / Instructions

This is homework #`r paste(hw_num)` of STAT 471/571/701. It will be **due on `r paste(hw_due_date)` by 11:59 PM** on Canvas. You can directly edit this file to add your answers. Submit the Rmd file, a PDF or word or HTML version with only 1 submission per HW team.


Solutions will be posted. Make sure to go through these files to pick up some tips.

```{r library, include=FALSE}
# add your library imports here:
library(dplyr)
library(leaps)
library(ggplot2)
library(glmnet)
library(reshape2)
```

## Problem 0

Review the code and concepts covered during lecture: model selection and penalized regression through elastic net. 

## Problem 1: Model Selection

Do ISLR, page 262, problem 8, and write up the answer here. This question is designed to help understanding of model selection through simulations. 

#### (a)
```{r}
set.seed(19)
n <- 100
x <- rnorm(n)
epsilon <- rnorm(n)
```

#### (b)
The betas are beta0=0.25, beta1=1.9, beta2=1.23, beta3=0.89
```{r}
Y <- 0.25 + 1.9 * x + 1.23 * x^2 + 0.89 * x^3 + epsilon
```

#### (c)
```{r}
df <- data.frame(Y, x, x^2, x^3, x^4, x^5, x^6, x^7, x^8, x^9, x^10)
models <- regsubsets(Y ~ ., df, nvmax = 10, method='exhaustive')

summ <- summary(models)

best_cp <- which.min(summ$cp)
best_bic <- which.min(summ$bic)
best_adjr2 <- which.max(summ$adjr2)
```
The best model according to BIC is using `r best_bic` predictors, according to CP using `r best_cp` predictors and using Adjusted R^2 `r best_adjr2` predictors.

```{r}
par(mfrow=c(3, 1), mar=c(2.5, 4, 0.5, 1), mgp=c(1.5, 0.5, 0))
plot(summ$cp, xlab="Number of predictors", 
     ylab="cp", col="red", type="p", pch=16)
plot(summ$bic, xlab="Number of predictors", 
     ylab="bic", col="blue", type="p", pch=16)
plot(summ$adjr2, xlab="Number of predictors", 
     ylab="adjr2", col="green", type="p", pch=16)
```

The coefficients of the best model (using x, x^2, x^3 predictors) are:
```{r}
coef(models, id = 3)
```

#### (d)
```{r}
models.f <- regsubsets(Y ~ ., df, nvmax = 10, method='forward')

summ.f <- summary(models.f)

best_cp.f <- which.min(summ.f$cp)
best_bic.f <- which.min(summ.f$bic)
best_adjr2.f <- which.max(summ.f$adjr2)
```
The best model according to BIC is using `r best_bic.f` predictors, according to CP using `r best_cp.f` predictors and using Adjusted R^2 `r best_adjr2.f` predictors.

```{r}
par(mfrow=c(3, 1), mar=c(2.5, 4, 0.5, 1), mgp=c(1.5, 0.5, 0))
plot(summ.f$cp, xlab="Number of predictors", 
     ylab="cp", col="red", type="p", pch=16)
plot(summ.f$bic, xlab="Number of predictors", 
     ylab="bic", col="blue", type="p", pch=16)
plot(summ.f$adjr2, xlab="Number of predictors", 
     ylab="adjr2", col="green", type="p", pch=16)
```
The coefficients of the best model (using 3 predictors) through forward selection are:
```{r}
coef(models.f, id = 3)
```

```{r}
models.b <- regsubsets(Y ~ ., df, nvmax = 10, method='backward')

summ.b <- summary(models.b)

best_cp.b <- which.min(summ.b$cp)
best_bic.b <- which.min(summ.b$bic)
best_adjr2.b <- which.max(summ.b$adjr2)
```
The best model according to BIC is using `r best_bic.b` predictors, according to CP using `r best_cp.b` predictors and using Adjusted R^2 `r best_adjr2.b` predictors.

```{r}
par(mfrow=c(3, 1), mar=c(2.5, 4, 0.5, 1), mgp=c(1.5, 0.5, 0))
plot(summ.b$cp, xlab="Number of predictors", 
     ylab="cp", col="red", type="p", pch=16)
plot(summ.b$bic, xlab="Number of predictors", 
     ylab="bic", col="blue", type="p", pch=16)
plot(summ.b$adjr2, xlab="Number of predictors", 
     ylab="adjr2", col="green", type="p", pch=16)
```
The coefficients of the best model (using 3 predictors) through backward selection are:
```{r}
coef(models.b, id = 3)
```

The results are the same for forward and backward selection for this particular choice of betas and seed. Although, the results may vary between forward and backward selection because forward starts with 0 predictors and grows and backward starts with all predictors and shrinks.

#### (e)
Without CV
```{r}
X.lasso <- matrix(data=c(x, x^2, x^3, x^4, x^5, x^6, x^7, x^8, x^9, x^10),nrow=100)
models.lasso <- glmnet(X.lasso, Y, alpha = 1)

plot(models.lasso)
```
With CV
```{r}
models.lasso.cv <- cv.glmnet(X.lasso, Y, alpha = 1)

plot(models.lasso.cv)
```

```{r}
plot(models.lasso.cv$lambda, models.lasso.cv$cvm, xlab=expression(lambda), ylab="Mean cv error", col="red", pch=16)
```
The LASSO coefficients using lambda.min = `r models.lasso.cv$lambda.min` are:
```{r}
coef(models.lasso.cv, s = "lambda.min")
```
The LASSO coefficients using lambda.1se = `r models.lasso.cv$lambda.1se` are:
```{r}
coef(models.lasso.cv, s = "lambda.1se")
```
We chose lambda.min to fit the model with the following coefficients:
```{r}
fit.min.lm <- lm(Y ~ x+x.2+x.3, data=df)
coef(fit.min.lm) # output lm estimates
```

#### (f)
```{r}
Y.new = 0.3 + 2 * x^7 + epsilon
df.new <- data.frame(Y.new, x, x^2, x^3, x^4, x^5, x^6, x^7, x^8, x^9, x^10)
models.new <- regsubsets(Y.new ~ ., df.new, nvmax = 10, method='exhaustive')

summ.new <- summary(models.new)

best_cp.new <- which.min(summ.new$cp)
best_bic.new <- which.min(summ.new$bic)
best_adjr2.new <- which.max(summ.new$adjr2)
```
The best model according to BIC is using `r best_bic.new` predictors, according to CP using `r best_cp.new` predictors and using Adjusted R^2 `r best_adjr2.new` predictors.

```{r}
par(mfrow=c(3, 1), mar=c(2.5, 4, 0.5, 1), mgp=c(1.5, 0.5, 0))
plot(summ.new$cp, xlab="Number of predictors", 
     ylab="cp", col="red", type="p", pch=16)
plot(summ.new$bic, xlab="Number of predictors", 
     ylab="bic", col="blue", type="p", pch=16)
plot(summ.new$adjr2, xlab="Number of predictors", 
     ylab="adjr2", col="green", type="p", pch=16)
```

The coefficients of the best model (using x^7 predictor) are:
```{r}
coef(models.new, id = 1)
```

LASSO Model
```{r}
X.lasso.new <- matrix(data=c(x, x^2, x^3, x^4, x^5, x^6, x^7, x^8, x^9, x^10),nrow=100)
models.lasso.new <- cv.glmnet(X.lasso.new, Y.new, alpha = 1)
plot(models.lasso.new)
```

```{r}
plot(models.lasso.new$lambda, models.lasso.new$cvm, xlab=expression(lambda), ylab="Mean cv error", col="red", pch=16)
```
The LASSO coefficients using lambda.min = `r models.lasso.new$lambda.min` are:
```{r}
coef(models.lasso.new, s = "lambda.min")
```
The LASSO coefficients using lambda.1se = `r models.lasso.new$lambda.1se` are:
```{r}
coef(models.lasso.new, s = "lambda.1se")
```
We chose lambda.min to fit the model with the following coefficients:
```{r}
fit.min.lm.new <- lm(Y.new ~ x.7, data=df)
coef(fit.min.lm.new)
```

## Problem 2: Regularization

Crime data continuation:  We use a subset of the crime data discussed in class, but only look at Florida and California. `crimedata` is available on Canvas; we show the code to clean here. 

```{r}
crime <- read.csv("CrimeData.csv", stringsAsFactors = F, na.strings = c("?"))
crime <- dplyr::filter(crime, state %in% c("FL", "CA"))
```

Our goal is to find the factors which relate to violent crime. This variable is included in crime as `crime$violentcrimes.perpop`.

**A)** EDA

* Clean the data first
* Prepare a set of sensible factors/variables that you may use to build a model
* Show the heatmap with mean violent crime by state. You may also show a couple of your favorite summary statistics by state through the heatmaps.
* Write a brief summary based on your EDA

```{r, results='hide'}
#Checking NAs
na_count <- sapply(crime, function(y) sum(length(which(is.na(y)))))
data.frame(na_count)
```

```{r, results='hide'}
#Removing NAs
crime2 <- crime[, -which(colMeans(is.na(crime)) > 0.5)]
na_count <- sapply(crime2, function(y) sum(length(which(is.na(y)))))
data.frame(na_count)
```

```{r, results='hide'}
#Only keep violent crimes
crime.final <- crime2[-c(106:121, 123)]
names(crime.final)
```

```{r, include=F}
#removed state, fold, community, num.urban, other.percap, num.underpov, num.vacant.house, pct.police.drugunits. same cleaning treatment as class example of cleandata.csv
crime.final.noCat <- crime.final[-c(307),-c(1:3, 14, 29, 31, 75, 105)]
```


```{r}
#Create Heatmap of USA crimerates
data.s <- crime.final %>%
  group_by(state) %>%
  summarise(
    mean.income=mean(med.income), 
    mean.unemp=mean(pct.unemployed),
    crime.rate=mean(violentcrimes.perpop, na.rm=TRUE), #ignore the missing values
    n=n())

#Create a new data frame with mean crime rate and corresponding state name
crimerate <- data.s[, c("state", "crime.rate")]

#Change abbreviations to names. eg: PA --> Pennsylvania, CA --> California
crimerate$region <- tolower(state.name[match(crimerate$state, state.abb)])

#Add the center coordinate for each state `state.center` contains the coordinate corresponding to `state.abb` in order.
crimerate$center_lat  <- state.center$x[match(crimerate$state, state.abb)]
crimerate$center_long <- state.center$y[match(crimerate$state, state.abb)]

#Load US map info
states <- map_data("state") 

#Combine the US map data with the crimerate data
map <- merge(states, crimerate, sort=FALSE, by="region", all.x=TRUE)

#Re-establish the point order
map <- map[order(map$order),]

ggplot(map, aes(x=long, y=lat, group=group))+
  geom_polygon(aes(fill=crime.rate))+
  geom_path()+ 
  geom_text(data=crimerate, aes(x=center_lat, y=center_long, group=NA, 
                             label=state, size=2), show.legend =FALSE)+
  scale_fill_continuous(limits=c(0, 2000),name="Mean Crime Rate",
                        low="light blue", high="dark blue", na.value="white")   
```
```{r}
#Mean income heatmap
income <- data.s[, c("state", "mean.income")]
#Change abbreviations to names. eg: PA --> Pennsylvania, CA --> California
income$region <- tolower(state.name[match(income$state, state.abb)])

#Add the center coordinate for each state `state.center` contains the coordinate corresponding to `state.abb` in order.
income$center_lat  <- state.center$x[match(income$state, state.abb)]
income$center_long <- state.center$y[match(income$state, state.abb)]

#Combine the US map data with the income data
map2 <- merge(states, income, sort=FALSE, by="region", all.x=TRUE)

#Re-establish the point order

ggplot(map2, aes(x=long, y=lat, group=group))+
  geom_polygon(aes(fill=mean.income))+
  geom_path()+ 
  geom_text(data=income, aes(x=center_lat, y=center_long, group=NA, 
                             label=state, size=2), show.legend =FALSE)+
  scale_fill_continuous(limits=c(1000, 60000),name="Mean Income",
                        low="pink", high="red", na.value="white")   
```
```{r}
# Mean unemployed percentage heatmap
unemp <- data.s[, c("state", "mean.unemp")]

#Change abbreviations to names. eg: PA --> Pennsylvania, CA --> California
unemp$region <- tolower(state.name[match(unemp$state, state.abb)])

#Add the center coordinate for each state `state.center` contains the coordinate corresponding to `state.abb` in order.
unemp$center_lat  <- state.center$x[match(unemp$state, state.abb)]
unemp$center_long <- state.center$y[match(unemp$state, state.abb)]

#Combine the US map data with the unemployment data
map3 <- merge(states, unemp, sort=FALSE, by="region", all.x=TRUE)

#Re-establish the point order
map3 <- map3[order(map3$order),]

ggplot(map3, aes(x=long, y=lat, group=group))+
  geom_polygon(aes(fill=mean.unemp))+
  geom_path()+ 
  geom_text(data=unemp, aes(x=center_lat, y=center_long, group=NA, 
                             label=state, size=2), show.legend =FALSE)+
  scale_fill_continuous(limits=c(0, 10),name="Mean Unemployment Percentage",
                        low="yellow", high="red", na.value = "white")   
```

```{r, include=F}
summary(crime.final)
```

A quick summary: We've excluded all states except CA and FL while removing NA's and non violent crimes from the data set. Florida seems to have a higher crime rate and a lower mean income. However, percent unemployment is lower. We'll have to perform additional analysis before arriving at any conclusion. 


**B)** Use LASSO to choose a reasonable, small model. Fit an OLS model with the variables obtained. The final model should only include variables with p-values < 0.05. Note: you may choose to use lambda 1se or lambda min to answer the following questions where apply. 

1. What is the model reported by LASSO? 

i) LASSO Model
```{r}
Y.crime <- crime.final.noCat[, 98]
X.crime <- model.matrix(violentcrimes.perpop~., data=crime.final.noCat)
crimes.lasso.cv <- cv.glmnet(X.crime, Y.crime, alpha = 1, nfolds=10)
plot(crimes.lasso.cv)
```

ii) Variable Estimation
```{r}
crimes.coef.min <- coef(crimes.lasso.cv, s="lambda.1se")  
crimes.coef.min <- crimes.coef.min[which(crimes.coef.min !=0),]   # get the non=zero coefficients

lasso.vars <- rownames(as.matrix(crimes.coef.min)) # shows only names, not estimates 
lasso.vars

```

We choose lambda1se = `r crimes.lasso.cv$lambda.1se` as our lambda after performing kfold cross validation to obtain a smaller set of variables than with lambdamin and arrive at a simpler model.  This is because we believe that many of these variables influence each other (beyond the scope of our assumption that variables are independent - many socioeconomic factors have a strong correlation in real life). It is best to arrive at a smallest as possible but still relevant set of variables to examine.

The model is 
```{r}
crimes.coef.min
```

2. What is the model after running OLS?

```{r}
crimes.lm.input <- as.formula(paste("violentcrimes.perpop", "~", paste(lasso.vars[-1], collapse = "+"))) # prepare for lm fomulae
crimes.lm.input

fit.crime.min.lm <- lm(crimes.lm.input, data=crime.final.noCat)
crimes.lm.output <- coef(fit.crime.min.lm) # output lm estimates
summary(fit.crime.min.lm) 

lm.error.1 <- mean((predict(fit.crime.min.lm, data=X.crime)-Y.crime)^2)
```
The OLS model is $$Y = 2012.949 + 13.956(race.pctblack) -22.678(pct.kids2parents) + 94.953(pct.kids.nvrmarried)$$

3. What is your final model, after excluding high p-value variables? You will need to use model selection method to obtain this final model. Make it clear what criterion/criteria you have used and justify why they are appropriate. 

Upon closer examination of the variables we are using, we notice that the p-values of all variables is < 0.05. This is most likely due to the fact that we've used lambda1se. Had we used lambdamin or another variable, the model is slightly more complex (it includes variables such as pct.house.vacant and num.in.shelters) of which some are above 0.05 and we would exclude. Our final model therefore remains the same as above and is:
$$Y = 2012.949 + 13.956(race.pctblack) -22.678(pct.kids2parents) + 94.953(pct.kids.nvrmarried)$$
Since the variable p vaules < 0.05 we chose this model. Otherwise, we would have performed subset selection.

**C)** Now, instead of Lasso, we want to consider how changing the value of alpha (i.e. mixing between Lasso and Ridge) will affect the model. Cross-validate between alpha and lambda, instead of just lambda. Note that the final model may have variables with p-values higher than 0.05; this is because we are optimizing for accuracy rather than parsimoniousness. 

1. What is your final elastic net model? What were the alpha and lambda values? What is the prediction error?

```{r}
train <- sample(1:nrow(X.crime), nrow(X.crime)/2)
test <- (-train)
Y.crime.test=Y.crime[test]
alphas <- rep(NA, 70)
lambdas <- rep(NA, 70)
errors <- rep(NA, 70)
count <- 1

for(a in (1:10)/10){
  for(l in c(0.001, 0.01, 0.1, 0, 1, 10, 100)){
    fit.model <- glmnet(X.crime[train ,], Y.crime[train], alpha=a, lambda= l)
    pred.model <- predict(fit.model, s=l, newx=X.crime[test,])
    errors[count] <- mean((pred.model-Y.crime.test)^2)
    alphas[count] <- a
    lambdas[count] <- l
    count <- count + 1
  }
}
```

We tested for alpha values ranging from 0.1 to 1 and lambdas in {0.001, 0.01, 0.1, 0, 1, 10, 100}. The model with the least prediction error = `r min(errors)` (mean squared prediction error) had alpha = `r alphas[which.min(errors)]` and lambda = `r lambdas[which.min(errors)]`

The final elastic model is:
```{r}
best.elastic <- glmnet(X.crime, Y.crime, alpha=alphas[which.min(errors)], lambda=lambdas[which.min(errors)])
best.elastic.coef <- coef(best.elastic, s="lambda.1se")  
best.elastic.coef <- best.elastic.coef[which(best.elastic.coef !=0),]

best.elastic.coef
```

2. Use the elastic net variables in an OLS model. What is the equation, and what is the prediction error.

The final equation has the following estimates:
```{r}
vars.elastic <- rownames(as.matrix(best.elastic.coef)) 
vars.elastic <- vars.elastic[-1]
lm.input.elastic <- as.formula(paste("violentcrimes.perpop", "~", paste(vars.elastic, collapse = "+"))) 

fit.min.lm.elastic <- lm(lm.input.elastic, data=crime.final.noCat)
lm.output.elastic <- summary(fit.min.lm.elastic)
lm.output.elastic

pred_err <- mean((predict(fit.min.lm.elastic, data=X.crime)-Y.crime)^2)
```
The Prediction error (mean square prediction error) is `r pred_err`.


3. Summarize your findings, with particular focus on the difference between the two equations.
 
Both the LASSO and Elastic Net chose the same variables and produced the same model. In the LASSO model, lambda was ~135 and alpha = 1. In the Elastic Net model, lambda was `r lambdas[which.min(errors)]` and alpha = `r alphas[which.min(errors)]`

**B+)** Repeat similar stepts as that of **B)** but start with the set of variables that also include all two way interactions

a) LASSO Model
```{r}
Y.crimeSQ <- crime.final.noCat[, 98]
X.crimeSQ <- model.matrix(violentcrimes.perpop~.+.*., data=crime.final.noCat)
crimes.lasso.cv.sq <- cv.glmnet(X.crimeSQ, Y.crimeSQ, alpha = 1, nfolds=10)
plot(crimes.lasso.cv.sq)
```

b) Variable Estimation
```{r}
coef.min.sq <- coef(crimes.lasso.cv.sq, s="lambda.1se") 
coef.min.sq <- coef.min.sq[which(coef.min.sq !=0),]   
lasso.vars.sq <- rownames(as.matrix(coef.min.sq)) 
```

```{r}
lm.input.sq <- as.formula(paste("violentcrimes.perpop", "~", paste(lasso.vars.sq[-1], collapse = "+"))) # prepare for lm fomulae

fit.min.lm.sq <- lm(lm.input.sq, data=crime.final.noCat)
lm.output.sq <- coef(fit.min.lm.sq) # output lm estimates
summary(fit.min.lm.sq)

s <- summary(fit.min.lm.sq)
lm.error.2 <- mean((predict(fit.min.lm.sq, data=X.crime)-Y.crime)^2)
```

1. How many variables do you have now?

There are `r length(s$coefficients[,1])` variables in this model.

2. Comparing the final models with the ones from **B)**, which one would you use? Commenting on your choice.
Comparing with the final model from B, we would choose the model from B because it is easier to interpret than the interacting variables in B+, has less complex interactions, and requires less data to obtain a prediction (3 variables as opposed to `r length(s$coefficients[,1])` in B+). The predicition errors are also not that far apart. Hence, The B model is our choice.
